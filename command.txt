conda create -n expose pip python=3.7

conda activate expose

conda install pytorch=1.6.0 torchvision=0.7.0 cudatoolkit=10.2 -c pytorch

pip install -r requirements.txt

"C:\Development\Anaconda3\envs\expose\Lib\site-packages\bezier\extra-dll\bezier-2e929504.dll"
をひとつ上の階層に

cd lighttrack\lib

python setup_windows.py build_ext --inplace
※スキップされたらcファイルを削除

python setup_cuda.py build_ext --inplace

cd ..\graph\torchlight

python setup.py install

cd ..\..\..\

--------------

Docker 版

https://docs.docker.jp/docker-for-windows/install.html#install-docker-desktop-on-windows














--------------

conda create -n expose2 pip python=3.6

conda activate expose2

conda install pytorch==1.5.0 torchvision==0.6.0 cudatoolkit=10.1 -c pytorch

pip install -r requirements.txt

build

python executor.py --img-dir E:\MMD\MikuMikuDance_v926x64\Work\201805_auto\01\burai\breast_mov_20210327_205648 --process expose,tracking --verbose 20 --log-mode 0 

python executor.py --img-dir E:\MMD\MikuMikuDance_v926x64\Work\201805_auto\01\burai\breast_mov_20210327_205648 --order-file E:\MMD\MikuMikuDance_v926x64\Work\201805_auto\01\burai\breast_mov_20210327_205648\breast.csv --process order,smooth,motion --body-motion 1 --hand-motion 1 --upper-motion 1 --center-scale 5 --smooth-key 1 --verbose 20 --log-mode 0

python executor.py --video-file E:\MMD\MikuMikuDance_v926x64\Work\201805_auto\01\burai\REN1.mp4 --process prepare,expose,tracking --body-motion 1 --hand-motion 1 --upper-motion 1 --center-scale 5 --smooth-key 1 --verbose 20 --log-mode 0

python executor.py --img-dir E:\MMD\MikuMikuDance_v926x64\Work\201805_auto\01\heart\heart_full5_mp4_20210608_074923 --order-file E:\MMD\MikuMikuDance_v926x64\Work\201805_auto\01\heart\heart_full5_mp4_20210608_074923\order.txt --process order,face,smooth,motion --body-motion 1 --hand-motion 1 --face-motion 1 --upper-motion 0 --center-scale 5 --smooth-key 1 --verbose 20 --log-mode 0


python executor.py --video-file "E:\MMD\MikuMikuDance_v926x64\Work\201805_auto\02\buster\buster_30fps_1100-1300.mp4" --process prepare,expose,tracking --verbose 20 --log-mode 0


python executor.py --video-file "E:\MMD\MikuMikuDance_v926x64\Work\201805_auto\01\burai\BF.avi" --process prepare,expose,tracking --verbose 20 --log-mode 0

----------

python executor.py --video-file E:\MMD\MikuMikuDance_v926x64\Work\201805_auto\03\bbf\bbf_1740-2740.mp4 --process prepare,expose,tracking --verbose 20 --log-mode 0

python executor.py --img-dir E:\MMD\MikuMikuDance_v926x64\Work\201805_auto\03\bbf\bbf_1740-2740_mp4_20210223_111446 --process expose,tracking --verbose 20 --log-mode 0

python executor.py --img-dir E:\MMD\MikuMikuDance_v926x64\Work\201805_auto\01\burai\BF_mp4_20210701_190611 --process smooth,motion --body-motion 1 --smooth-key 1 --verbose 20 --log-mode 0

----------


https://expose.is.tue.mpg.de/
https://smpl-x.is.tue.mpg.de/
Model DL

-----------
for MMD

pip install numpy-quaternion
pip install bezier

-------------
for 顔検知

(expose) c:\MMD\expose_mmd>pip install dlib
(expose) c:\MMD\expose_mmd>pip install imutils

python face.py --video-path samples/girl2/girl2_30fps.avi --verbose 10


---------
for lighttrack

pip install tensorflow-gpu==1.15
pip install cython opencv-python pillow matplotlib

(expose) c:\MMD\lighttrack_mmd\lib>python setup_windows.py build_ext --inplace

(expose) c:\MMD\lighttrack_mmd\lib>python setup_cuda.py build_ext --inplace
※ファイル指定は cuのみでOK

(expose) c:\MMD\lighttrack_mmd\graph\torchlight>python setup.py install

pip install "C:\MMD\frankmocap_mmd\scripts\setproctitle-1.2.1-cp37-cp37m-win_amd64.whl"

pip install scikit-image

---------

右端のtvfilter

if明度調節→ifコントラスト→シャープネス→ダストアンドスクラッチ
が一番よっさそ


グレスケで　全体再生のうちの　2/4　3/4　の位置をグレスケで取得する
双方を比較して　数値がさほど変化がなければカメラが固定なので　自動調整有効にする

グレスケ処理して　ヒストグラム取得　カーブの傾向でどうするか決めるってのが
ちょっと　ヒストグラムの取得周りが謎だけど　一番妥当な解決策ﾄｵﾓﾜﾚﾙ

FF階調しかないものを　FF階調前提の処理をしても
FFの範囲
擬似的にレンジを広げてから　トーン伸張をしてから　FFに戻すのが大事
実写系映像の認識の問題は　シャドーで隠れるが殆どなんで　　シャドー部分だけを伸張するのが
大事大事
暗い部分の階調を広げる

less今日 02:35
曲線弄れたなら
もうｲｹﾙ
kumaris今日 02:35
やってることは　RGBカラーの　反比例曲線的算出につき
少し考えてみるのをオススメ

kumaris今日 02:36
但しアクセラレーションを使わないので
処理時間がやべえくらい増えるとおもわるる
ﾊﾟｲﾁｮﾝ
less今日 02:36
処理的にはLUTが一番早いと思われる
kumaris今日 02:36
ﾀｶｼ
less今日 02:37
最初に、適当なそういう曲線を作る式を使ってLUTを生成して、あとは辞書処理


